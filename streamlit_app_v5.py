# streamlit_app_v5.py
import streamlit as st
import requests
import pandas as pd
from PIL import Image
from io import BytesIO
import time
import plotly.express as px
import plotly.graph_objects as go

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AIå›¾åƒåˆ†ç±»å™¨ - å®Œå…¨ä½“ V5",
    page_icon="ğŸ”®",
    layout="wide"
)

# åç«¯APIåœ°å€
API_URL = "http://localhost:8000"
API_KEY = "123456"  # ä½¿ç”¨ä½ çš„æœ‰æ•ˆAPIå¯†é’¥

def make_authenticated_request(url, files=None, method='GET'):
    """å‘é€å¸¦è®¤è¯çš„APIè¯·æ±‚"""
    headers = {"X-API-Key": API_KEY}
    
    try:
        if method == 'GET':
            response = requests.get(url, headers=headers, timeout=10)
        elif method == 'POST':
            response = requests.post(url, files=files, headers=headers, timeout=30)
        else:
            return None
            
        return response
    except requests.exceptions.RequestException as e:
        st.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
        return None

def get_system_info():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    response = make_authenticated_request(f"{API_URL}/stats")
    if response and response.status_code == 200:
        return response.json()
    return None

# def get_prediction_history():
#     """è·å–é¢„æµ‹å†å²è®°å½•"""
#     # ç”±äºV5åç«¯ç›®å‰æ²¡æœ‰æä¾›å†å²è®°å½•æŸ¥è¯¢æ¥å£
#     # è¿™é‡Œå…ˆè¿”å›ç©ºåˆ—è¡¨ï¼Œç­‰æ·»åŠ è¯¥æ¥å£åå†å®ç°
#     return []

def main():
    st.title("ğŸ”® AIå›¾åƒåˆ†ç±»å™¨ - å®Œå…¨ä½“ V5")
    st.markdown("åŸºäºFastAPI V5åç«¯çš„å…¨åŠŸèƒ½å›¾åƒåˆ†ç±»ç³»ç»Ÿ")
    
    # ä¾§è¾¹æ  - ç³»ç»Ÿä¿¡æ¯
    st.sidebar.header("ğŸ“Š ç³»ç»Ÿä¿¡æ¯")
    
    # å®æ—¶ç³»ç»ŸçŠ¶æ€
    with st.sidebar.expander("å®æ—¶çŠ¶æ€", expanded=True):
        system_info = get_system_info()
        if system_info:
            st.metric("æ€»é¢„æµ‹æ¬¡æ•°", system_info.get('total_predictions', 0))
            st.metric("ç³»ç»ŸçŠ¶æ€", "ğŸŸ¢ åœ¨çº¿")
        else:
            st.metric("ç³»ç»ŸçŠ¶æ€", "ğŸ”´ ç¦»çº¿")
            st.error("æ— æ³•è¿æ¥åˆ°åç«¯æœåŠ¡")
    
    # ä¸»ç•Œé¢æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“· å›¾åƒé¢„æµ‹", "âš¡ æ€§èƒ½å¯¹æ¯”", "ğŸ“Š é¢„æµ‹å†å²", "â„¹ï¸ ç³»ç»Ÿä¿¡æ¯"])
    
    # æ ‡ç­¾é¡µ1: å›¾åƒé¢„æµ‹
    with tab1:
        st.header("ğŸ¯ å¤šæ¨¡å‹å›¾åƒé¢„æµ‹")
        st.markdown("é€‰æ‹©ä¸åŒçš„ä¼˜åŒ–æ¨¡å‹è¿›è¡Œå›¾åƒåˆ†ç±»")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            uploaded_file = st.file_uploader(
                "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶", 
                type=['png', 'jpg', 'jpeg'],
                help="æ”¯æŒ T-shirtã€è£¤å­ã€åŒ…ç­‰10ç±»æ—¶å°šå•å“è¯†åˆ«"
            )
            
            if uploaded_file is not None:
                image = Image.open(uploaded_file)
                st.image(image, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_column_width=True)
        
        with col2:
            st.subheader("æ¨¡å‹é€‰æ‹©")
            model_option = st.radio(
                "é€‰æ‹©é¢„æµ‹æ¨¡å‹:",
                ["PyTorch åŸç‰ˆ", "TorchScript ä¼˜åŒ–", "é‡åŒ–æ¨¡å‹", "ONNX è¿è¡Œæ—¶"],
                help="ä¸åŒæ¨¡å‹åœ¨ç²¾åº¦å’Œé€Ÿåº¦ä¸Šæœ‰æ‰€å·®å¼‚"
            )
            
            model_endpoints = {
                "PyTorch åŸç‰ˆ": "/predict",
                "TorchScript ä¼˜åŒ–": "/predict-scripted", 
                "é‡åŒ–æ¨¡å‹": "/predict-quantized",
                "ONNX è¿è¡Œæ—¶": "/predict-onnx"
            }
            
            if st.button("å¼€å§‹é¢„æµ‹", type="primary", use_container_width=True):
                if uploaded_file is not None:
                    with st.spinner(f"ğŸ”„ æ­£åœ¨ä½¿ç”¨ {model_option} è¿›è¡Œåˆ†æ..."):
                        try:
                            # å‡†å¤‡å›¾ç‰‡æ•°æ®
                            img_byte_arr = BytesIO()
                            image.save(img_byte_arr, format="PNG")
                            img_byte_arr.seek(0)
                            
                            # è°ƒç”¨é€‰æ‹©çš„æ¨¡å‹æ¥å£
                            endpoint = model_endpoints[model_option]
                            files = {"file": ("image.png", img_byte_arr, "image/png")}
                            response = make_authenticated_request(
                                f"{API_URL}{endpoint}", 
                                files=files, 
                                method='POST'
                            )
                            
                            if response and response.status_code == 200:
                                result = response.json()
                                
                                # æ˜¾ç¤ºç»“æœ
                                st.success("âœ… é¢„æµ‹å®Œæˆï¼")
                                
                                # ç»“æœå¡ç‰‡
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("è¯†åˆ«ç»“æœ", result['class'])
                                with col2:
                                    st.metric("ç½®ä¿¡åº¦", f"{result['confidence']:.2%}")
                                with col3:
                                    st.metric("æ¨ç†æ—¶é—´", f"{result['inference_time_ms']}ms")
                                
                                # ç½®ä¿¡åº¦å¯è§†åŒ–
                                st.subheader("ç½®ä¿¡åº¦åˆ†å¸ƒ")
                                fig = go.Figure(data=[
                                    go.Bar(x=[result['class']], y=[result['confidence']],
                                          marker_color='lightblue')
                                ])
                                fig.update_layout(
                                    title=f"{result['class']} çš„ç½®ä¿¡åº¦",
                                    yaxis_title="ç½®ä¿¡åº¦",
                                    yaxis_range=[0, 1],
                                    showlegend=False
                                )
                                st.plotly_chart(fig, use_container_width=True)
                                
                            else:
                                st.error("âŒ é¢„æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥åç«¯æœåŠ¡çŠ¶æ€")
                                
                        except Exception as e:
                            st.error(f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}")
                else:
                    st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å›¾ç‰‡æ–‡ä»¶")
    
    # æ ‡ç­¾é¡µ2: æ€§èƒ½å¯¹æ¯”
    with tab2:
        st.header("âš¡ æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
        st.markdown("å¯¹æ¯”ä¸åŒæ¨¡å‹åœ¨ç›¸åŒå›¾ç‰‡ä¸Šçš„æ¨ç†æ€§èƒ½")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            benchmark_file = st.file_uploader(
                "é€‰æ‹©æµ‹è¯•å›¾ç‰‡", 
                type=['png', 'jpg', 'jpeg'],
                key="benchmark"
            )
            
            if benchmark_file is not None:
                benchmark_image = Image.open(benchmark_file)
                st.image(benchmark_image, caption="æ€§èƒ½æµ‹è¯•å›¾ç‰‡", use_container_width=True)
        
        with col2:
            st.subheader("åŸºå‡†æµ‹è¯•é…ç½®")
            if st.button("å¼€å§‹æ€§èƒ½æµ‹è¯•", type="primary", use_container_width=True):
                if benchmark_file is not None:
                    with st.spinner("ğŸ”„ æ­£åœ¨è¿è¡ŒåŸºå‡†æµ‹è¯•ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´..."):
                        try:
                            # å‡†å¤‡å›¾ç‰‡æ•°æ®
                            img_byte_arr = BytesIO()
                            benchmark_image.save(img_byte_arr, format="PNG")
                            img_byte_arr.seek(0)
                            
                            # è°ƒç”¨åŸºå‡†æµ‹è¯•æ¥å£
                            files = {"file": ("benchmark.png", img_byte_arr, "image/png")}
                            response = make_authenticated_request(
                                f"{API_URL}/predict-benchmark", 
                                files=files, 
                                method='POST'
                            )
                            
                            if response and response.status_code == 200:
                                benchmark_result = response.json()
                                
                                st.success("âœ… åŸºå‡†æµ‹è¯•å®Œæˆï¼")
                                
                                # æ˜¾ç¤ºæœ€å¿«æ¨¡å‹
                                fastest = benchmark_result.get('fastest_model', {})
                                st.info(f"ğŸš€ æœ€å¿«æ¨¡å‹: **{fastest.get('name', 'N/A')}** "
                                      f"({fastest.get('time_ms', 'N/A')}ms)")
                                
                                # æ€§èƒ½å¯¹æ¯”å›¾è¡¨
                                st.subheader("æ¨ç†æ—¶é—´å¯¹æ¯”")
                                times_data = benchmark_result.get('inference_times_ms', {})
                                if times_data:
                                    df_times = pd.DataFrame({
                                        'Model': list(times_data.keys()),
                                        'Time (ms)': list(times_data.values())
                                    })
                                    
                                    fig = px.bar(
                                        df_times, 
                                        x='Model', 
                                        y='Time (ms)',
                                        title="å„æ¨¡å‹æ¨ç†æ—¶é—´å¯¹æ¯”",
                                        color='Time (ms)',
                                        color_continuous_scale='Viridis'
                                    )
                                    st.plotly_chart(fig, use_container_width=True)
                                
                                # åŠ é€Ÿæ¯”å±•ç¤º
                                st.subheader("æ€§èƒ½åŠ é€Ÿæ¯”")
                                speed_data = benchmark_result.get('speed_comparison', {})
                                if speed_data:
                                    for model, speedup in speed_data.items():
                                        st.write(f"- **{model}**: {speedup}")
                                
                            else:
                                st.error("âŒ åŸºå‡†æµ‹è¯•å¤±è´¥")
                                
                        except Exception as e:
                            st.error(f"âŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {str(e)}")
                else:
                    st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æµ‹è¯•å›¾ç‰‡")
    
    # æ ‡ç­¾é¡µ3: é¢„æµ‹å†å²
    with tab3:
        st.header("ğŸ“Š é¢„æµ‹å†å²è®°å½•")
        st.markdown("æŸ¥çœ‹å†å²é¢„æµ‹è®°å½•å’Œç»Ÿè®¡ä¿¡æ¯")
        
        # è¿™é‡Œå¯ä»¥æ˜¾ç¤ºä»æ•°æ®åº“è·å–çš„å†å²è®°å½•
        # éœ€è¦åç«¯æä¾›å¯¹åº”çš„æ¥å£
        history = get_prediction_history()
        
        if history:
            df_history = pd.DataFrame(history)
            st.dataframe(df_history, use_container_width=True)
            
            # ç®€å•çš„ç»Ÿè®¡å›¾è¡¨
            if not df_history.empty:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("æ¨¡å‹ä½¿ç”¨åˆ†å¸ƒ")
                    model_counts = df_history['model_used'].value_counts()
                    fig_pie = px.pie(
                        values=model_counts.values,
                        names=model_counts.index,
                        title="å„æ¨¡å‹ä½¿ç”¨æ¯”ä¾‹"
                    )
                    st.plotly_chart(fig_pie, use_container_width=True)
                
                with col2:
                    st.subheader("ç±»åˆ«è¯†åˆ«åˆ†å¸ƒ")
                    class_counts = df_history['predicted_class'].value_counts()
                    fig_bar = px.bar(
                        x=class_counts.index,
                        y=class_counts.values,
                        title="å„ç±»åˆ«è¯†åˆ«æ¬¡æ•°",
                        labels={'x': 'ç±»åˆ«', 'y': 'æ¬¡æ•°'}
                    )
                    st.plotly_chart(fig_bar, use_container_width=True)
        else:
            st.info("ğŸ“ æš‚æ— é¢„æµ‹å†å²è®°å½•")
            st.markdown("""
            **å¾…å¼€å‘åŠŸèƒ½ï¼š**
            - å†å²é¢„æµ‹è®°å½•æŸ¥è¯¢
            - é¢„æµ‹ç»“æœç»Ÿè®¡åˆ†æ  
            - æ¨¡å‹æ€§èƒ½è¶‹åŠ¿åˆ†æ
            """)
    
    # æ ‡ç­¾é¡µ4: ç³»ç»Ÿä¿¡æ¯
    with tab4:
        st.header("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("åç«¯æœåŠ¡çŠ¶æ€")
            if system_info:
                st.success("ğŸŸ¢ æœåŠ¡åœ¨çº¿")
                st.json(system_info)
            else:
                st.error("ğŸ”´ æœåŠ¡ç¦»çº¿")
            
            st.subheader("APIç«¯ç‚¹è¯´æ˜")
            endpoints_info = {
                "/predict": "PyTorch åŸç‰ˆæ¨¡å‹",
                "/predict-scripted": "TorchScript ä¼˜åŒ–æ¨¡å‹", 
                "/predict-quantized": "é‡åŒ–ä¼˜åŒ–æ¨¡å‹",
                "/predict-onnx": "ONNX è¿è¡Œæ—¶æ¨¡å‹",
                "/predict-benchmark": "å¤šæ¨¡å‹æ€§èƒ½å¯¹æ¯”",
                "/stats": "ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"
            }
            
            for endpoint, desc in endpoints_info.items():
                st.write(f"`{endpoint}` - {desc}")
        
        with col2:
            st.subheader("æ”¯æŒè¯†åˆ«çš„ç±»åˆ«")
            classes = [
                "T-shirt/top", "Trouser", "Pullover", "Dress", "Coat",
                "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"
            ]
            
            for i, class_name in enumerate(classes, 1):
                st.write(f"{i}. {class_name}")
            
            st.subheader("æŠ€æœ¯ç‰¹æ€§")
            features = [
                "âœ… å¤šæ¨¡å‹æ¨ç†æ”¯æŒ",
                "âœ… å®æ—¶æ€§èƒ½å¯¹æ¯”", 
                "âœ… æ•°æ®åº“æŒä¹…åŒ–",
                "âœ… Redisç¼“å­˜ç»Ÿè®¡",
                "âœ… åå°ä»»åŠ¡å¤„ç†",
                "âœ… APIå¯†é’¥è®¤è¯",
                "âœ… è¯¦ç»†æ—¥å¿—è®°å½•"
            ]
            
            for feature in features:
                st.write(feature)

if __name__ == "__main__":
    main()